{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yake\n",
    "import langdetect\n",
    "import importlib.resources\n",
    "from yake import KeywordExtractor\n",
    "import stopwordsiso\n",
    "from langdetect import detect as lang_detect, DetectorFactory\n",
    "\n",
    "# Setting a seed for the language detector to ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "lang_detect(\"warm-up\")  # Initial detection to warm up the language detector\n",
    "\n",
    "langdetect_profiles = os.path.join(importlib.resources.files(langdetect).__str__(), \"profiles\")\n",
    "languages_langdetect = set(os.listdir(langdetect_profiles))  # Supported languages by langdetect\n",
    "\n",
    "# Supported languages by YAKE for keyword extraction\n",
    "languages_yake = {'ar', 'bg', 'br', 'cz', 'da', 'de', 'el', 'en', 'es', 'et', 'fa', \n",
    " 'fi', 'fr', 'hi', 'hr', 'hu', 'hy', 'id','it','ja','lt','lv','nl', \n",
    " 'no','pl','pt','ro','ru','sk','sl','sv','tr','uk','zh'}\n",
    "\n",
    "# Checking for any additional YAKE languages by inspecting the stopwords directory\n",
    "stop_words_path = os.path.join(importlib.resources.files(yake).__str__(), \"StopwordsList\")\n",
    "if os.path.exists(stop_words_path):\n",
    "    additional_yake_languages = set(re.findall(r\"stopwords_([a-z]+)\\.txt\", \"\\n\".join(os.listdir(stop_words_path))))\n",
    "    languages_yake.update(additional_yake_languages)\n",
    "\n",
    "# Dictionary to map langdetect languages to YAKE languages\n",
    "LangCode = str\n",
    "KeywordsList = set[str]\n",
    "yake_lang_mapping: dict[str, tuple[LangCode, KeywordsList | None]] = {}\n",
    "\n",
    "# Mapping YAKE languages to corresponding langdetect languages\n",
    "for yake_lang in languages_yake:\n",
    "    for langdetect_lang in languages_langdetect:\n",
    "        if langdetect_lang.find(yake_lang) != -1:  # Partial match to handle variations in language codes\n",
    "            yake_lang_mapping[langdetect_lang] = (yake_lang, None)\n",
    "\n",
    "# Identifying langdetect languages that couldn't be mapped directly to YAKE\n",
    "unmapped_langdetect_languages = languages_langdetect - yake_lang_mapping.keys()\n",
    "\n",
    "# Finding languages that have stopwords available in stopwords-iso\n",
    "stopwordsiso_languages: set[str] = stopwordsiso._core._LANGS\n",
    "languages_with_stopwords = stopwordsiso_languages.intersection(unmapped_langdetect_languages)\n",
    "\n",
    "# Updating the mapping with languages that have stopwords available\n",
    "yake_lang_mapping.update({\n",
    "    lang: (lang, stopwordsiso.stopwords(lang)) for lang in languages_with_stopwords\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(\n",
    "        corpus: str,\n",
    "        number_of_keywords: int = 10,\n",
    "        max_ngram_size: int = 3,\n",
    "        window_size: int = 1,\n",
    "        ) -> set[str]:\n",
    "    \n",
    "    lang_code: str = lang_detect(corpus)\n",
    "    keywords: list[tuple] = []\n",
    "    if lang_code in yake_lang_mapping:\n",
    "        lang_code, stopwords = yake_lang_mapping[lang_code]\n",
    "        \n",
    "        deduplication_threshold = 0.5\n",
    "        deduplication_algo = \"seqm\"\n",
    "        extractor = KeywordExtractor(\n",
    "            lan=lang_code, \n",
    "            n=max_ngram_size, \n",
    "            dedupLim=deduplication_threshold, \n",
    "            dedupFunc=deduplication_algo, \n",
    "            windowsSize=window_size, \n",
    "            top=number_of_keywords, \n",
    "            features=None,\n",
    "            stopwords=stopwords\n",
    "        )\n",
    "\n",
    "        keywords = extractor.extract_keywords(corpus)\n",
    "        \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning \"\\\n",
    "\"competitions. Details about the transaction remain somewhat vague, but given that Google is hosting its Cloud \"\\\n",
    "\"Next conference in San Francisco this week, the official announcement could come as early as tomorrow. \"\\\n",
    "\"Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the acquisition is happening. \"\\\n",
    "\"Google itself declined 'to comment on rumors'. Kaggle, which has about half a million data scientists on its platform, \"\\\n",
    "\"was founded by Goldbloom  and Ben Hamner in 2010. \"\\\n",
    "\"The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, \"\\\n",
    "\"it has managed to stay well ahead of them by focusing on its specific niche. \"\\\n",
    "\"The service is basically the de facto home for running data science and machine learning competitions. \"\\\n",
    "\"With Kaggle, Google is buying one of the largest and most active communities for data scientists - and with that, \"\\\n",
    "\"it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow \"\\\n",
    "\"and other projects). Kaggle has a bit of a history with Google, too, but that's pretty recent. Earlier this month, \"\\\n",
    "\"Google and Kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. \"\\\n",
    "\"That competition had some deep integrations with the Google Cloud Platform, too. Our understanding is that Google \"\\\n",
    "\"will keep the service running - likely under its current name. While the acquisition is probably more about \"\\\n",
    "\"Kaggle's community than technology, Kaggle did build some interesting tools for hosting its competition \"\\\n",
    "\"and 'kernels', too. On Kaggle, kernels are basically the source code for analyzing data sets and developers can \"\\\n",
    "\"share this code on the platform (the company previously called them 'scripts'). \"\\\n",
    "\"Like similar competition-centric sites, Kaggle also runs a job board, too. It's unclear what Google will do with \"\\\n",
    "\"that part of the service. According to Crunchbase, Kaggle raised $12.5 million (though PitchBook says it's $12.75) \"\\\n",
    "\"since its   launch in 2010. Investors in Kaggle include Index Ventures, SV Angel, Max Levchin, Naval Ravikant, \"\\\n",
    "\"Google chief economist Hal Varian, Khosla Ventures and Yuri Milner \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_keywords(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
